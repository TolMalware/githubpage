<link rel="stylesheet" href="main.css">
<h3 id="классификация-данных">Классификация данных</h3>

<script type="text/javascript" async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p>В этом разделе вашей задачей является написание простого классификатора, который бы выводил неразмеченные новости в следующем порядке: сначала идут интересные для нас новости, затем те, которые мы бы возможно прочитали, и в конце  - неинтересные новости.</p>

<p>Итак, у нас есть корпус, состоящий из размеченных и неразмеченных документов (новостей). Возникает два вопроса: «Каким образом каждой свежей новости присвоить одну из меток (классов)?» и «Как оценить нашу классификацию?».</p>

<p>Для более качественной классификации мы будем использовать <strong>наивный байесовский классификатор</strong>. Если вы не знакомы с теоремой Байеса, то можете прочитать исчерпывающее объяснение от <a href="http://yudkowsky.net/rational/bayes">Юдковски</a> (есть перевод и на русский язык). Также, для пояснения работы наивного байесовского классификатора я буду ссылаться на статью в <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">Википедии</a>.</p>

<p>Итак, вопрос на который мы отвечаем: «Какова вероятность, что документ <script type="math/tex">D</script> принадлежит классу <script type="math/tex">C</script>?» или в более строгой записи: чему равно <script type="math/tex">P(D \mid C)</script>? Документом <script type="math/tex">D</script> у нас является новость, а классом <script type="math/tex">C</script> - одна из трех возможных меток: «Интересно», «Не интересно», «Возможно».</p>

<p>Документ представляется множеством независимых слов (это лишь предположение, которого мы придерживаемся. В действительности слова не являются независимыми, например, слово «Петербург» имеет более высокую вероятность идти в паре со словом «Санкт»), где вероятность того, что <script type="math/tex">i</script>-ое слово данного документа принадлежит классу <script type="math/tex">C</script> равна <script type="math/tex">P(w_i \mid C)</script>. Таким образом, вероятность для данного документа и класса <script type="math/tex">C</script> равна:</p>

<script type="math/tex; mode=display">P(D|C) = \prod_{i} P(w_i|C)</script>

<p>По теореме Байеса получим:</p>

<script type="math/tex; mode=display">P(C|D) = \frac{P(C)P(D|C)}{P(D)}</script>

<p>Можно заметить, что знаменатель не зависит от <script type="math/tex">C</script>, поэтому получим:</p>

<div class="admonition legend">
  <p class="first admonition-title"><strong>Замечание</strong></p>
  <p class="last">Хотя с точки зрения теории вероятностей эта формула неверная, так как сумма вероятностей не будет равна 1, но с точки зрения работы классификатора она нас полностью устраивает.</p>
</div>

<script type="math/tex; mode=display">P(C|D) \propto P(C)P(D|C) = P(C)\prod_{i}P(w_i|C)</script>

<p>Вы можете догадаться, что если появится слово, которого мы раньше не встречали, то <script type="math/tex">\prod_{i}P(w_i \mid C) = 0</script>, а следовательно и <script type="math/tex">P(C \mid D) = 0</script>.</p>

<p>Одним из типичных решений является использование Lidstone smoothing (<script type="math/tex">% <![CDATA[
\alpha < 1 %]]></script>) или Laplacian smoothing (<script type="math/tex">\alpha = 1</script>):</p>

<script type="math/tex; mode=display">P(w_i \mid C = c) = \frac{n_{i,c} + \alpha}{n_c + \alpha d}</script>

<p>где:</p>
<ul>
  <li><script type="math/tex">n_{i,c}</script> - число наблюдений признака <script type="math/tex">w_i</script> для класса <script type="math/tex">c</script>;</li>
  <li><script type="math/tex">n_c</script> - число наблюдений признака <script type="math/tex">w_i</script> среди всех классов;</li>
  <li><script type="math/tex">\alpha</script> - параметр сглаживания;</li>
  <li><script type="math/tex">d</script> - размерность вектора признаков <script type="math/tex">W = \left \langle w_1,...,w_d \right \rangle</script>.</li>
</ul>

<p>Еще одним «техническим» трюком является логарифмирование, чтобы произведение маленьких величин не привело к обращению всего произведения в ноль:</p>

<script type="math/tex; mode=display">\ln P(C|D) \propto \ln P(C) + \sum_i \ln P(w_i|C)</script>

<p>Итак, наша итоговая модель будет выглядеть следующим образом:</p>

<script type="math/tex; mode=display">\hat{y} = argmax_c\Big(\ln P(C=c) + \sum_i \ln P(w_i|C = c) \Big)</script>

<h3 id="пример"><em>Пример</em></h3>

<p>Давайте рассмотрим простой пример классификации сообщений с двумя классами «Positive» и «Negative». Пусть у нас имеется следующая обучающая выборка:</p>

<div class="admonition legend">
  <p class="first admonition-title"><strong>Замечание</strong></p>
  <p class="last">Данные для примера можно найти <a href="https://stevenloria.com/simple-text-classification/">тут</a>.</p>
</div>

<table>
  <thead>
    <tr>
      <th>Сообщение</th>
      <th>Метка класса</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>I love this sandwich</td>
      <td>Positive</td>
    </tr>
    <tr>
      <td>This is an amazing place</td>
      <td>Positive</td>
    </tr>
    <tr>
      <td>I feel very good about these beers</td>
      <td>Positive</td>
    </tr>
    <tr>
      <td>This is my best work</td>
      <td>Positive</td>
    </tr>
    <tr>
      <td>What an awesome view</td>
      <td>Positive</td>
    </tr>
    <tr>
      <td>I do not like this restaurant</td>
      <td>Negative</td>
    </tr>
    <tr>
      <td>I am tired of this stuff</td>
      <td>Negative</td>
    </tr>
    <tr>
      <td>I can’t deal with this</td>
      <td>Negative</td>
    </tr>
    <tr>
      <td>He is my sworn enemy</td>
      <td>Negative</td>
    </tr>
    <tr>
      <td>My boss is horrible</td>
      <td>Negative</td>
    </tr>
  </tbody>
</table>

<p>Для начала найдем априорные вероятности классов: <script type="math/tex">P(C=pos) = 5/10 = 0.5</script> и <script type="math/tex">P(C=neg) = 5/10 = 0.5</script>.</p>

<p>Теперь составим таблицу, в которой будут следующие колонки (о двух дополнительных колонках см. ниже):</p>
<ul>
  <li>слова из обучающей выборки;</li>
  <li>сколько раз слово встретилось в классе «Positive»;</li>
  <li>сколько раз слово встретилось в классе «Negative».</li>
</ul>

<table>
  <thead>
    <tr>
      <th>Слово</th>
      <th>«<script type="math/tex">+</script>»</th>
      <th>«<script type="math/tex">-</script>»</th>
      <th>$$P(w_i \mid pos)$$</th>
      <th>$$P(w_i \mid neg)$$</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>about</td>
      <td>1</td>
      <td>0</td>
      <td>0.032</td>
      <td>0.016</td>
    </tr>
    <tr>
      <td>am</td>
      <td>0</td>
      <td>1</td>
      <td>0.016</td>
      <td>0.032</td>
    </tr>
    <tr>
      <td>amazing</td>
      <td>1</td>
      <td>0</td>
      <td>0.032</td>
      <td>0.016</td>
    </tr>
    <tr>
      <td>an</td>
      <td>2</td>
      <td>0</td>
      <td>0.049</td>
      <td>0.016</td>
    </tr>
    <tr>
      <td>awesome</td>
      <td>1</td>
      <td>0</td>
      <td>0.032</td>
      <td>0.016</td>
    </tr>
    <tr>
      <td>beers</td>
      <td>1</td>
      <td>0</td>
      <td>0.032</td>
      <td>0.016</td>
    </tr>
    <tr>
      <td>best</td>
      <td>1</td>
      <td>0</td>
      <td>0.032</td>
      <td>0.016</td>
    </tr>
    <tr>
      <td>boss</td>
      <td>0</td>
      <td>1</td>
      <td>0.016</td>
      <td>0.032</td>
    </tr>
    <tr>
      <td>cant</td>
      <td>0</td>
      <td>1</td>
      <td>0.016</td>
      <td>0.032</td>
    </tr>
    <tr>
      <td>deal</td>
      <td>0</td>
      <td>1</td>
      <td>0.016</td>
      <td>0.032</td>
    </tr>
    <tr>
      <td>do</td>
      <td>0</td>
      <td>1</td>
      <td>0.016</td>
      <td>0.032</td>
    </tr>
    <tr>
      <td>enemy</td>
      <td>0</td>
      <td>1</td>
      <td>0.016</td>
      <td>0.032</td>
    </tr>
    <tr>
      <td>feel</td>
      <td>1</td>
      <td>0</td>
      <td>0.032</td>
      <td>0.016</td>
    </tr>
    <tr>
      <td>good</td>
      <td>1</td>
      <td>0</td>
      <td>0.032</td>
      <td>0.016</td>
    </tr>
    <tr>
      <td>he</td>
      <td>0</td>
      <td>1</td>
      <td>0.016</td>
      <td>0.032</td>
    </tr>
    <tr>
      <td>horrible</td>
      <td>0</td>
      <td>1</td>
      <td>0.016</td>
      <td>0.032</td>
    </tr>
    <tr>
      <td>i</td>
      <td>2</td>
      <td>3</td>
      <td>0.049</td>
      <td>0.064</td>
    </tr>
    <tr>
      <td>is</td>
      <td>2</td>
      <td>2</td>
      <td>0.049</td>
      <td>0.048</td>
    </tr>
    <tr>
      <td>like</td>
      <td>0</td>
      <td>1</td>
      <td>0.016</td>
      <td>0.032</td>
    </tr>
    <tr>
      <td>love</td>
      <td>1</td>
      <td>0</td>
      <td>0.032</td>
      <td>0.016</td>
    </tr>
    <tr>
      <td>my</td>
      <td>1</td>
      <td>2</td>
      <td>0.032</td>
      <td>0.048</td>
    </tr>
    <tr>
      <td>not</td>
      <td>0</td>
      <td>1</td>
      <td>0.016</td>
      <td>0.032</td>
    </tr>
    <tr>
      <td>of</td>
      <td>0</td>
      <td>1</td>
      <td>0.016</td>
      <td>0.032</td>
    </tr>
    <tr>
      <td>place</td>
      <td>1</td>
      <td>0</td>
      <td>0.032</td>
      <td>0.016</td>
    </tr>
    <tr>
      <td>restaurant</td>
      <td>0</td>
      <td>1</td>
      <td>0.016</td>
      <td>0.032</td>
    </tr>
    <tr>
      <td>sandwich</td>
      <td>1</td>
      <td>0</td>
      <td>0.032</td>
      <td>0.016</td>
    </tr>
    <tr>
      <td>stuff</td>
      <td>0</td>
      <td>1</td>
      <td>0.016</td>
      <td>0.032</td>
    </tr>
    <tr>
      <td>sworn</td>
      <td>0</td>
      <td>1</td>
      <td>0.016</td>
      <td>0.032</td>
    </tr>
    <tr>
      <td>these</td>
      <td>1</td>
      <td>0</td>
      <td>0.032</td>
      <td>0.016</td>
    </tr>
    <tr>
      <td>this</td>
      <td>3</td>
      <td>3</td>
      <td>0.065</td>
      <td>0.064</td>
    </tr>
    <tr>
      <td>tired</td>
      <td>0</td>
      <td>1</td>
      <td>0.016</td>
      <td>0.032</td>
    </tr>
    <tr>
      <td>very</td>
      <td>1</td>
      <td>0</td>
      <td>0.032</td>
      <td>0.016</td>
    </tr>
    <tr>
      <td>view</td>
      <td>1</td>
      <td>0</td>
      <td>0.032</td>
      <td>0.016</td>
    </tr>
    <tr>
      <td>what</td>
      <td>1</td>
      <td>0</td>
      <td>0.032</td>
      <td>0.016</td>
    </tr>
    <tr>
      <td>with</td>
      <td>0</td>
      <td>1</td>
      <td>0.016</td>
      <td>0.032</td>
    </tr>
    <tr>
      <td>work</td>
      <td>1</td>
      <td>0</td>
      <td>0.032</td>
      <td>0.016</td>
    </tr>
  </tbody>
</table>

<p>Итак, размер вектора признаков равен <script type="math/tex">d=36</script> (число уникальных слов во всей выборке). Также найдем число слов относящихся  к классу «Positive» и к классу «Negative»: <script type="math/tex">n_{pos} = 25</script> и <script type="math/tex">n_{neg} = 26</script> (суммы по второму и третьему столбцу). Теперь мы можем посчитать вероятность встретить слово в каждом из классов <script type="math/tex">P(w_i \mid C = c)</script> (4 и 5 столбцы).</p>

<p>Нам этого достаточно для того, чтобы классифицировать новые сообщения. Пусть имеется такой набор тестовых данных:</p>

<table>
  <thead>
    <tr>
      <th>Сообщение</th>
      <th>Метка класса</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>The beer was good</td>
      <td>Positive</td>
    </tr>
    <tr>
      <td>I do not enjoy my job</td>
      <td>Negative</td>
    </tr>
    <tr>
      <td>I ain’t feeling dandy today</td>
      <td>Negative</td>
    </tr>
    <tr>
      <td>I feel amazing</td>
      <td>Positive</td>
    </tr>
    <tr>
      <td>Gary is a friend of mine</td>
      <td>Positive</td>
    </tr>
    <tr>
      <td>I can’t believe I’m doing this</td>
      <td>Negative</td>
    </tr>
  </tbody>
</table>

<p>В качестве примера рассмотрим классификацию первого сообщения.</p>

<div class="admonition legend">
  <p class="first admonition-title"><strong>Замечание</strong></p>
  <p class="last">Если слова нет в словаре, то есть, среди всех слов из обучающей выборки, то оно никак не повлияет на результат классификации. Таким образом, будем считать его вероятность для обоих классов равной нулю.</p>
</div>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
\ln P(pos|D) &= \ln P(pos) + \ln P(the|pos) + \ln P(beer|pos) + \ln P(was|pos) + \ln P(good|pos) \\ 
&= -0.693 + 0 + 0 + 0 - 3.417 = -4.110 \\
\ln P(neg|D) &= \ln P(neg) + \ln P(the|neg) + \ln P(beer|neg) + \ln P(was|neg) + \ln P(good|neg) \\
&= -0.693 - 0 + 0 + 0 - 4.127 = -4.820 \\
\hat{y} &= argmax_c\Big(\ln P(pos|D), \ln P(neg|D)\Big) = \ln P(pos|D) \Rightarrow pos
\end{aligned} %]]></script>

<p>Если мы классифицируем остальные сообщения, то получим, что мы верно классифицировали 5 из 6 сообщений. Таким образом, точность нашего классификатора составила 83% на тестовой выборке.</p>
